{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stemmer"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\u6982\u89c8","text":"\ud83e\uddd0 Knowledge QA LLM"},{"location":"#_1","title":"\u7b80\u4ecb","text":"<p>\u200b\u57fa\u4e8e\u200b\u672c\u5730\u200b\u77e5\u8bc6\u5e93\u200b+LLM\u200b\u7684\u200b\u95ee\u7b54\u200b\u7cfb\u7edf\u200b\u3002\u200b\u8be5\u9879\u200b\u76ee\u7684\u200b\u601d\u8def\u200b\u662f\u200b\u7531\u200blangchain-ChatGLM\u200b\u542f\u53d1\u200b\u800c\u200b\u6765\u200b\u3002</p> <ul> <li>\u200b\u7f18\u7531\u200b\uff1a<ul> <li>\u200b\u4e4b\u524d\u200b\u4f7f\u7528\u200b\u8fc7\u200b\u8fd9\u4e2a\u200b\u9879\u76ee\u200b\uff0c\u200b\u611f\u89c9\u200b\u4e0d\u662f\u200b\u592a\u200b\u7075\u6d3b\u200b\uff0c\u200b\u90e8\u7f72\u200b\u4e0d\u592a\u200b\u53cb\u597d\u200b\u3002</li> <li>\u200b\u501f\u9274\u200b\u5982\u4f55\u200b\u7528\u5927\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u6784\u5efa\u200b\u4e00\u4e2a\u200b\u77e5\u8bc6\u200b\u95ee\u7b54\u200b\u7cfb\u7edf\u200b\u4e2d\u200b\u601d\u8def\u200b\uff0c\u200b\u5c1d\u8bd5\u200b\u4ee5\u6b64\u200b\u4f5c\u4e3a\u200b\u5b9e\u8df5\u200b\u3002</li> </ul> </li> <li>\u200b\u4f18\u52bf\u200b\uff1a<ul> <li>\u200b\u6574\u4e2a\u200b\u9879\u76ee\u200b\u4e3a\u200b\u6a21\u5757\u5316\u200b\u914d\u7f6e\u200b\uff0c\u200b\u4e0d\u200b\u4f9d\u8d56\u200b<code>lanchain</code>\u200b\u5e93\u200b\uff0c\u200b\u5404\u200b\u90e8\u5206\u200b\u53ef\u200b\u8f7b\u6613\u200b\u66ff\u6362\u200b\uff0c\u200b\u4ee3\u7801\u200b\u7b80\u5355\u200b\u6613\u61c2\u200b\u3002</li> <li>\u200b\u9664\u200b\u9700\u8981\u200b\u5355\u72ec\u200b\u90e8\u7f72\u200b\u5927\u200b\u6a21\u578b\u200b\u63a5\u53e3\u200b\u5916\u200b\uff0c\u200b\u5176\u4ed6\u200b\u90e8\u5206\u200b\u7528\u200bCPU\u200b\u5373\u53ef\u200b\u3002</li> <li>\u200b\u652f\u6301\u200b\u5e38\u89c1\u200b\u683c\u5f0f\u200b\u6587\u6863\u200b\uff0c\u200b\u5305\u62ec\u200btxt\u3001md\u3001pdf, docx, pptx, excel\u200b\u7b49\u7b49\u200b\u3002\u200b\u5f53\u7136\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u200b\u81ea\u5b9a\u4e49\u200b\u652f\u6301\u200b\u5176\u4ed6\u200b\u7c7b\u578b\u200b\u6587\u6863\u200b\u3002</li> </ul> </li> </ul>"},{"location":"#_2","title":"\u6574\u4f53\u200b\u6d41\u7a0b","text":""},{"location":"#_3","title":"\u89e3\u6790\u200b\u6587\u6863\u200b\u5e76\u200b\u5b58\u50a8\u200b\u5728\u200b\u6570\u636e\u5e93","text":"<pre><code>flowchart LR\n\nA([Documents]) --ExtractText--&gt; B([sentences])\nB --Embeddings--&gt; C([Embeddings])\nC --Store--&gt; D[(DataBase)]</code></pre>"},{"location":"#_4","title":"\u68c0\u7d22\u200b\u5e76\u200b\u56de\u7b54\u200b\u95ee\u9898","text":"<pre><code>flowchart LR\nE([Query]) --Embedding--&gt; F([Embeddings]) --&gt; H[(Database)] --Search--&gt; G([Context])\nE --&gt; I([Prompt])\nG --&gt; I --&gt; J([LLM]) --&gt; K([Answer])</code></pre>"},{"location":"#_5","title":"\u4f7f\u7528\u200b\u7684\u200b\u5de5\u5177","text":"<ul> <li>\u200b\u6587\u6863\u200b\u5206\u6790\u200b: <code>extract_office_content</code>, <code>rapidocr_pdf</code>, <code>rapidocr_onnxruntime</code></li> <li>\u200b\u63d0\u53d6\u200b\u8bed\u4e49\u200b\u5411\u91cf\u200b: <code>moka-ai/m3e-small</code></li> <li>\u200b\u5411\u91cf\u200b\u5b58\u50a8\u200b: <code>sqlite</code></li> <li>\u200b\u5411\u91cf\u200b\u68c0\u7d22\u200b: <code>faiss</code></li> <li>UI\u200b\u642d\u5efa\u200b: <code>streamlit&gt;=1.25.0</code></li> </ul>"},{"location":"changelog/","title":"\u66f4\u65b0\u200b\u65e5\u5fd7","text":""},{"location":"changelog/#2023-10-15-v0010-update","title":"2023-10-15 v0.0.10 update","text":"<ul> <li>\u200b\u5f53\u200b\u4e0d\u80fd\u200b\u4ece\u200b\u6587\u6863\u200b\u4e2d\u200b\u641c\u7d22\u200b\u5230\u200b\u4efb\u4f55\u200b\u6709\u6548\u200b\u4fe1\u606f\u200b\u65f6\u200b\uff0c\u200b\u4f1a\u200b\u76f4\u63a5\u200b\u8c03\u7528\u200b\u6a21\u578b\u200b\u672c\u8eab\u200b\u7684\u200b\u80fd\u529b\u200b\u3002</li> <li>\u200b\u5b8c\u5584\u200b\u6587\u6863\u200b\uff0c\u200b\u6dfb\u52a0\u200b\u8d85\u200b\u53c2\u6570\u200b\u7684\u200b\u89e3\u91ca\u200b</li> <li>\u200b\u57fa\u4e8e\u200berniebot\u200b\u5e93\u200b\uff0c\u200b\u7edf\u4e00\u200b\u6587\u5fc3\u200b\u4e00\u200b\u8a00\u200b\u7248\u672c\u200b\u548c\u200b\u4ed3\u5e93\u200b\u4e3b\u200b\u5206\u652f\u200b\u7248\u672c\u200b</li> </ul>"},{"location":"changelog/#2023-09-07-v009-update","title":"2023-09-07 v0.0.9 update","text":"<ul> <li>\u200b\u89e3\u51b3\u200b\u591a\u4eba\u200b\u4e0a\u4f20\u200b\u7684\u200b\u6587\u6863\u200b\uff0c\u200b\u4f1a\u200b\u88ab\u200b\u5176\u4ed6\u4eba\u200b\u641c\u5230\u200b\u7684\u200b\u95ee\u9898\u200b</li> <li>\u200b\u4f18\u5316\u200bUI\u200b\u754c\u9762\u200b</li> </ul>"},{"location":"changelog/#2023-08-11-v007-update","title":"2023-08-11 v0.0.7 update","text":"<ul> <li>\u200b\u4f18\u5316\u200b\u5e03\u5c40\u200b\uff0c\u200b\u53bb\u6389\u200b\u63d2\u4ef6\u200b\u9009\u9879\u200b\uff0c\u200b\u5c06\u200b\u63d0\u53d6\u200b\u5411\u91cf\u200b\u6a21\u578b\u200b\u9009\u9879\u200b\u653e\u5230\u200b\u4e3b\u9875\u200b\u90e8\u5206\u200b</li> <li>\u200b\u5c06\u200b\u63d0\u793a\u200b\u8bed\u200b\u82f1\u8bed\u200b\u5316\u200b\uff0c\u200b\u4fbf\u4e8e\u200b\u4ea4\u6d41\u200b\u4f7f\u7528\u200b\u3002</li> <li>\u200b\u6dfb\u52a0\u200b\u9879\u76ee\u200blogo: \ud83e\uddd0</li> <li>\u200b\u66f4\u65b0\u200bCLI\u200b\u4f7f\u7528\u200b\u4ee3\u7801\u200b</li> </ul>"},{"location":"changelog/#2023-08-05-v006-update","title":"2023-08-05 v0.0.6 update","text":"<ul> <li>\u200b\u9002\u914d\u200b\u66f4\u200b\u591a\u200b\u6a21\u578b\u200b\u63a5\u53e3\u200b\uff0c\u200b\u5305\u62ec\u200b\u5728\u7ebf\u200b\u5927\u200b\u6a21\u578b\u200b\u63a5\u53e3\u200b\uff0c\u200b\u4f8b\u5982\u200b\u6587\u5fc3\u200b\u4e00\u200b\u8a00\u200b</li> <li>\u200b\u6dfb\u52a0\u200b\u63d0\u53d6\u200b\u7279\u5f81\u5411\u91cf\u200b\u7684\u200b\u72b6\u6001\u200b\u63d0\u793a\u200b</li> </ul>"},{"location":"changelog/#2023-08-04-v005-update","title":"2023-08-04 v0.0.5 update","text":"<ul> <li>\u200b\u4fee\u590d\u200b\u4e86\u200b\u63d2\u5165\u200b\u6570\u636e\u5e93\u200b\u6570\u636e\u200b\u91cd\u590d\u200b\u7684\u200b\u95ee\u9898\u200b\u3002</li> </ul>"},{"location":"changelog/#2023-07-29-v004-update","title":"2023-07-29 v0.0.4 update","text":"<ul> <li>\u200b\u57fa\u4e8e\u200b<code>streamlit==1.25.0</code>\u200b\u4f18\u5316\u200bUI</li> <li>\u200b\u4f18\u5316\u200b\u4ee3\u7801\u200b</li> <li>\u200b\u5f55\u5236\u200bUI GIF demo</li> </ul>"},{"location":"changelog/#2023-07-28-v003-update","title":"2023-07-28 v0.0.3 update","text":"<ul> <li>\u200b\u5b8c\u6210\u200b\u6587\u4ef6\u200b\u89e3\u6790\u200b\u90e8\u5206\u200b</li> </ul>"},{"location":"changelog/#2023-07-25-v002-update","title":"2023-07-25 v0.0.2 update","text":"<ul> <li>\u200b\u89c4\u8303\u200b\u73b0\u6709\u200b\u76ee\u5f55\u200b\u7ed3\u6784\u200b\uff0c\u200b\u66f4\u52a0\u200b\u7d27\u51d1\u200b\uff0c\u200b\u63d0\u53d6\u200b\u90e8\u5206\u200b\u53d8\u91cf\u200b\u5230\u200b<code>config.yaml</code>\u200b\u4e2d\u200b</li> <li>\u200b\u5b8c\u5584\u200b\u8bf4\u660e\u200b\u6587\u6863\u200b</li> </ul>"},{"location":"online_demo/","title":"\u5728\u7ebf\u200bdemo","text":""},{"location":"online_demo/#_1","title":"\u7b80\u4ecb","text":"<p>\u200b\u5728\u7ebf\u200bdemo\u200b\u662f\u200b\u57fa\u4e8e\u200b\u767e\u5ea6\u200b\u7684\u200bAI Studio\u200b\u5e73\u53f0\u200b\u642d\u5efa\u200b\uff0c\u200b\u57fa\u4e8e\u200b\u6587\u5fc3\u200b\u4e00\u8a00\u5927\u200b\u6a21\u578b\u200b\u7684\u200b\u63a5\u53e3\u200b\u642d\u5efa\u200b\u3002</p> <p>\u200b\u56e0\u4e3a\u200b\u8be5\u200b\u9879\u76ee\u200b\u6838\u5fc3\u200b\u5728\u4e8e\u200b\u5229\u7528\u200b\u5927\u200b\u6a21\u578b\u200b\u7684\u200b\u603b\u7ed3\u200b\u548c\u200b\u63d0\u53d6\u200b\u80fd\u529b\u200b\uff0c\u200b\u4e3b\u6253\u200b\u79bb\u7ebf\u200b\u79c1\u6709\u200b\u90e8\u7f72\u200b\uff0c\u200b\u4f46\u662f\u200b\u4e00\u76f4\u200b\u6ca1\u6709\u200b\u4e00\u4e2a\u200b\u5728\u7ebf\u200bdemo\u200b\u4f9b\u200b\u5927\u5bb6\u200b\u67e5\u770b\u200b\u6548\u679c\u200b\u3002\u200b\u56e0\u6b64\u200b\u6709\u200b\u4e86\u200b\u57fa\u4e8e\u200b\u6587\u5fc3\u200b\u4e00\u8a00\u7248\u200b\u7684\u200b \ud83e\uddd0 Knowledge QA LLM\u3002</p>"},{"location":"online_demo/#demo","title":"Demo\u200b\u6e90\u7801","text":"<p>\u200b\u57fa\u4e8e\u200b<code>erniebot</code>\u200b\u5e93\u6765\u200b\u642d\u5efa\u200b\u7684\u200b\uff0c\u200b\u5982\u9700\u200b\u4f7f\u7528\u200b\uff0c\u200b\u9700\u8981\u200b\u9274\u6743\u200b\uff0c\u200b\u63d0\u4f9b\u200b**Access Token**\uff0c\u200b\u5177\u4f53\u200b\u6559\u7a0b\u200b\uff0c\u200b\u53c2\u89c1\u200b\uff1alink</p> <p>\u200b\u5730\u5740\u200b\uff1a https://aistudio.baidu.com/projectdetail/6675380?contributionType=1</p>"},{"location":"online_demo/#demo_1","title":"\u5728\u7ebf\u200bDemo","text":"<p>Note</p> <p>\u200b\u8be5\u200bDemo\u200b\u4e3b\u8981\u200b\u4fa7\u91cd\u200b\u67e5\u770b\u200b\u6548\u679c\u200b\uff0c\u200b\u81f3\u4e8e\u200b\u5de5\u7a0b\u5316\u200b\u5219\u200b\u5dee\u200b\u4e00\u4e9b\u200b\u3002</p> <p>\u200b\u57fa\u4e8e\u200b\u6587\u5fc3\u200b\u4e00\u200b\u8a00\u200bAPI\u200b\u7684\u200b\u6587\u6863\u200b\u77e5\u8bc6\u200b\u95ee\u7b54\u200b\u7cfb\u7edf\u200b: https://aistudio.baidu.com/application/detail/8138</p>"},{"location":"quickstart/","title":"\u5feb\u901f\u200b\u5f00\u59cb","text":""},{"location":"quickstart/#1","title":"1. \u200b\u514b\u9686\u200b\u6574\u4e2a\u200b\u9879\u76ee\u200b\u5230\u200b\u672c\u5730","text":"<pre><code>git clone https://github.com/RapidAI/Knowledge-QA-LLM.git\n</code></pre>"},{"location":"quickstart/#2","title":"2. \u200b\u5b89\u88c5\u200b\u8fd0\u884c\u200b\u73af\u5883","text":"<pre><code>cd Knowledge-QA-LLM\npip install -r requirements.txt\n</code></pre>"},{"location":"quickstart/#3","title":"3. \u200b\u4e0b\u8f7d\u200b\u63d0\u53d6\u200b\u5411\u91cf\u200b\u6a21\u578b\u200b\u5230\u200b\u672c\u5730","text":"<p>\u200b\u672c\u200b\u9879\u76ee\u200b\u76ee\u524d\u200b\u4ee5\u200bMoka-AI\u200b\u7684\u200bm3e\u200b\u6a21\u578b\u200b\u4f5c\u4e3a\u200b\u63d0\u53d6\u200b\u7279\u5f81\u5411\u91cf\u200b\u7684\u200b\u4e3b\u8981\u200b\u6a21\u578b\u200b\uff0c\u200b\u5f53\u7136\u200b\u5176\u4ed6\u200b\u6a21\u578b\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u200b\u81ea\u884c\u200b\u914d\u7f6e\u200b\u3002</p> <p>\u200b\u5c06\u200b<code>moka-ai/m3e-small</code>\u200b\u4e0b\u8f7d\u200b\u4e0b\u6765\u200b\u653e\u5230\u200b<code>assets/models/m3e-small</code>\u200b\u76ee\u5f55\u200b\u4e0b\u200b\uff0c\u200b\u4e0b\u8f7d\u200b\u547d\u4ee4\u200b\u5982\u4e0b\u200b\uff1a</p> <pre><code>from sentence_transformers import SentenceTransformer\n\n# \u200b\u6307\u5b9a\u200bcache_dir\u200b\u5373\u53ef\u200b\nmodel = SentenceTransformer(\"moka-ai/m3e-small\", cache_folder=\"assets/models\")\n\n# \u200b\u9a8c\u8bc1\u200b\u662f\u5426\u200b\u53ef\u7528\u200b\nsentences = [\"* Moka \u200b\u6b64\u200b\u6587\u672c\u200b\u5d4c\u5165\u200b\u6a21\u578b\u200b\u7531\u200b MokaAI \u200b\u8bad\u7ec3\u200b\u5e76\u200b\u5f00\u6e90\u200b\uff0c\u200b\u8bad\u7ec3\u200b\u811a\u672c\u200b\u4f7f\u7528\u200b uniem\",]\nembeddings = model.encode(sentences)\nfor sentence, embedding in zip(sentences, embeddings):\n    print(\"Sentence:\", sentence)\n    print(\"Embedding:\", embedding)\n    print(\"\")\n</code></pre>"},{"location":"quickstart/#4-llm-api","title":"4. \u200b\u914d\u7f6e\u200bLLM API\u200b\u63a5\u53e3","text":"<p>\u200b\u9996\u5148\u200b\u9700\u8981\u200b\u5355\u72ec\u200b\u5728\u200b\u672c\u5730\u200b\u90e8\u7f72\u200b\u5927\u200b\u6a21\u578b\u200b\uff0c\u200b\u4ee5\u200bAPI\u200b\u65b9\u5f0f\u200b\u542f\u52a8\u200b\u3002\u200b\u4ee5\u200bChatGLM-6B\u200b\u4e3a\u4f8b\u200b\uff0c\u200b\u5177\u4f53\u200b\u53ef\u200b\u53c2\u8003\u200bChatGLM2-6B API</p> <p>\u200b\u968f\u540e\u200b\uff0c<code>knowledge_qa_llm/llm/chatglm2_6b.py</code>\u200b\u662f\u200b\u8c03\u7528\u200b\u4e0a\u200b\u4e00\u6b65\u200bLLM\u200b\u63a5\u53e3\u200b\u7684\u200b\u7c7b\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u81ea\u5df1\u200b\u4f7f\u7528\u200b\u7684\u200bLLM\uff0c\u200b\u6ca1\u6709\u200b\u8be5\u200b\u6587\u4ef6\u200b\uff0c\u200b\u53ef\u200b\u81ea\u884c\u200b\u5b9e\u73b0\u200b\uff0c\u200b\u4fdd\u8bc1\u200b\u8f93\u5165\u200b\u548c\u200b\u8f93\u51fa\u200b\u4e0e\u200b\u73b0\u6709\u200b\u7684\u200b\u4e00\u81f4\u200b\u5373\u53ef\u200b\u3002</p>"},{"location":"quickstart/#5-configyaml","title":"5. \u200b\u66f4\u6539\u200b<code>config.yaml</code>\u200b\u914d\u7f6e\u6587\u4ef6","text":"<p>\u200b\u5c06\u200b\u8c03\u7528\u200bChatGLM-6B\u200b\u7684\u200b<code>llm_api</code>\u200b\u7684\u200burl\u200b\u5199\u200b\u5230\u200b<code>knowledge_qa_llm/config.yaml</code>\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b</p> <pre><code>LLM_API:\n  ChatGLM2_6B: your_api\n</code></pre>"},{"location":"quickstart/#6","title":"6. \u200b\u8fd0\u884c","text":"<p>Note</p> <p>streamlit\u200b\u6846\u67b6\u200b\u7684\u200b\u542f\u52a8\u200b\uff0c\u200b\u4e0d\u200b\u53ef\u4ee5\u200b\u7528\u200b<code>python webui.py</code>\u200b\u65b9\u5f0f\u200b\u542f\u52a8\u200b\uff0c\u200b\u5fc5\u987b\u200b\u7528\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u542f\u52a8\u200b\u3002</p>"},{"location":"quickstart/#ui-demo","title":"UI Demo","text":"<pre><code>streamlit run webui.py\n</code></pre>"},{"location":"quickstart/#cli-demo","title":"CLI Demo","text":"<pre><code>python cli.py\n</code></pre>"},{"location":"road_map/","title":"RaodMap","text":""},{"location":"road_map/#standard-evaluation-process","title":"Standard Evaluation Process","text":"<p>Before proceeding with feature development and strategy optimization, we need a standard evaluation process to ensure all the features and strategies we introduce are effective.</p> <p>Create testsets using any dataset with advanced models and Ragas, then validate solution effectiveness using basic models.</p>"},{"location":"road_map/#feature-development-and-strategy-optimization","title":"Feature Development and Strategy Optimization","text":"<ol> <li>BM25 Keyword Search</li> <li>Hybrid Search (BM25 + Vector)</li> <li>GraphRAG</li> <li>ReRanking</li> <li>Query Rewriting</li> <li>Small-to-big</li> <li>...</li> </ol>"},{"location":"sponsor/","title":"Sponsor","text":""},{"location":"sponsor/#_1","title":"\u5199\u200b\u5728\u200b\u524d\u9762","text":"<p>I like open source and AI technology because I think open source and AI will bring convenience and help to people in need, and will also make the world a better place. By donating to these projects, you can join me in making AI bring warmth and beauty to more people.</p> <p>\u200b\u6211\u200b\u559c\u6b22\u200b\u5f00\u6e90\u200b\uff0c\u200b\u559c\u6b22\u200bAI\u200b\u6280\u672f\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6211\u200b\u8ba4\u4e3a\u200b\u5f00\u6e90\u200b\u548c\u200bAI\u200b\u4f1a\u4e3a\u200b\u6709\u200b\u9700\u8981\u200b\u7684\u200b\u4eba\u200b\u5e26\u6765\u200b\u65b9\u4fbf\u200b\u548c\u200b\u5e2e\u52a9\u200b\uff0c\u200b\u4e5f\u200b\u4f1a\u200b\u8ba9\u200b\u8fd9\u4e2a\u200b\u4e16\u754c\u200b\u53d8\u5f97\u200b\u66f4\u597d\u200b\u3002\u200b\u901a\u8fc7\u200b\u5bf9\u200b\u8fd9\u4e9b\u200b\u9879\u76ee\u200b\u7684\u200b\u6350\u8d60\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u548c\u200b\u6211\u200b\u4e00\u9053\u200b\u8ba9\u200bAI\u200b\u4e3a\u200b\u66f4\u200b\u591a\u200b\u4eba\u200b\u5e26\u6765\u200b\u6e29\u6696\u200b\u548c\u200b\u7f8e\u597d\u200b\u3002</p>"},{"location":"sponsor/#rapidai","title":"\u77e5\u8bc6\u200b\u661f\u7403\u200bRapidAI\u200b\u79c1\u4eab\u200b\u7fa4","text":"<p>\u200b\u8fd9\u91cc\u200b\u7684\u200b\u63d0\u95ee\u200b\u4f1a\u200b\u4f18\u5148\u200b\u5f97\u5230\u200b\u56de\u7b54\u200b\u548c\u200b\u652f\u6301\u200b\uff0c\u200b\u4e5f\u200b\u4f1a\u200b\u4eab\u53d7\u200b\u5230\u200bRapidAI\u200b\u7ec4\u7ec7\u200b\u540e\u7eed\u200b\u6301\u7eed\u200b\u4f18\u8d28\u200b\u7684\u200b\u670d\u52a1\u200b\uff0c\u200b\u6b22\u8fce\u200b\u5927\u5bb6\u200b\u7684\u200b\u52a0\u5165\u200b\u3002</p>"},{"location":"sponsor/#alipay-reward-or-wechat-reward","title":"\u652f\u4ed8\u5b9d\u200b\u6216\u200b\u5fae\u4fe1\u200b\u6253\u8d4f\u200b (Alipay reward or WeChat reward)","text":"<p>\u200b\u901a\u8fc7\u200b\u652f\u4ed8\u5b9d\u200b\u6216\u8005\u200b\u5fae\u4fe1\u200b\u7ed9\u200b\u4f5c\u8005\u200b\u6253\u8d4f\u200b\uff0c\u200b\u8bf7\u200b\u5199\u200b\u597d\u200b\u5907\u6ce8\u200b\u3002 Give the author a reward through Alipay or WeChat.</p>"},{"location":"sponsor/#buy-me-a-coffee","title":"Buy me a Coffee","text":"<p>If you are not in mainland China, you can also support the author through:</p>"},{"location":"blog/2023/09/11/%E8%87%AA%E5%AE%9A%E4%B9%89llm-api/","title":"\u81ea\u5b9a\u4e49\u200bLLM API","text":""},{"location":"blog/2023/09/11/%E8%87%AA%E5%AE%9A%E4%B9%89llm-api/#_1","title":"\u5f15\u8a00","text":"<p>\u200b\u8be5\u9879\u200b\u76ee\u7684\u200bLLM\u200b\u90e8\u5206\u200b\u662f\u200b\u72ec\u7acb\u200b\u7684\u200b\uff0c\u200b\u7528\u6237\u200b\u53ef\u200b\u5728\u200b knowledge_qa_llm/llm \u200b\u81ea\u5b9a\u4e49\u200b\u914d\u7f6e\u200b\u6240\u200b\u9700\u200b\u7684\u200bLLM\u200b\u63a5\u53e3\u200b\u3002</p> <p>\u200b\u4e0b\u9762\u200b\u4ee5\u200b\u81ea\u5b9a\u4e49\u200b\u652f\u6301\u200bInterLM-7b\u200b\u5927\u200b\u6a21\u578b\u200b\u4e3a\u4f8b\u200b\uff0c\u200b\u8bf4\u660e\u200b\u5982\u4f55\u200b\u652f\u6301\u200b\u7684\u200b\u3002\u200b\u524d\u63d0\u200b\u662f\u200b\u672c\u5730\u200b\u6ee1\u8db3\u200b\u90e8\u7f72\u200bLLM\u200b\u7684\u200b\u63a8\u7406\u200b\u6761\u4ef6\u200b\u3002</p>"},{"location":"blog/2023/09/11/%E8%87%AA%E5%AE%9A%E4%B9%89llm-api/#_2","title":"\u6b65\u9aa4\u200b\u5982\u4e0b","text":""},{"location":"blog/2023/09/11/%E8%87%AA%E5%AE%9A%E4%B9%89llm-api/#1-llm","title":"1. \u200b\u90e8\u7f72\u200bLLM\u200b\u6a21\u578b\u200b\u5230\u200b\u672c\u5730","text":"<p>\u200b\u5177\u4f53\u200b\u5982\u4f55\u200b\u4e0b\u8f7d\u200b\uff0c\u200b\u53c2\u89c1\u200bHugging Face\u200b\u4e2d\u200binternlm-7b\u3002</p>"},{"location":"blog/2023/09/11/%E8%87%AA%E5%AE%9A%E4%B9%89llm-api/#2","title":"2. \u200b\u7f16\u5199\u200b\u6a21\u578b\u200b\u7684\u200b\u90e8\u7f72\u200b\u63a8\u7406\u200b\u4ee3\u7801","text":"<p>\u200b\u8fd9\u200b\u4e00\u70b9\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200bChatGLMAPI\u200b\u7684\u200b\u5b9e\u73b0\u200b\u3002\u200b\u53ea\u200b\u9700\u8981\u200b\u66ff\u6362\u200b\u6a21\u578b\u200b\u52a0\u8f7d\u200b\u90e8\u5206\u200b\u4e3a\u200bInternLM\u200b\u7684\u200b\u5373\u53ef\u200b\u3002\u200b\u5177\u4f53\u200b\u5982\u4e0b\u200b\uff1a</p> <pre><code>from fastapi import FastAPI, Request\nfrom transformers import AutoTokenizer, AutoModel\nimport uvicorn, json, datetime\nimport torch\n\nDEVICE = \"cuda\"\nDEVICE_ID = \"0\"\nCUDA_DEVICE = f\"{DEVICE}:{DEVICE_ID}\" if DEVICE_ID else DEVICE\n\n\ndef torch_gc():\n    if torch.cuda.is_available():\n        with torch.cuda.device(CUDA_DEVICE):\n            torch.cuda.empty_cache()\n            torch.cuda.ipc_collect()\n\n\napp = FastAPI()\n\n\n@app.post(\"/\")\nasync def create_item(request: Request):\n    global model, tokenizer\n    json_post_raw = await request.json()\n    json_post = json.dumps(json_post_raw)\n    json_post_list = json.loads(json_post)\n    prompt = json_post_list.get('prompt')\n    history = json_post_list.get('history')\n    max_length = json_post_list.get('max_length')\n    top_p = json_post_list.get('top_p')\n    temperature = json_post_list.get('temperature')\n    response, history = model.chat(tokenizer,\n                                prompt,\n                                history=history,\n                                max_new_tokens=max_length if max_length else 2048,\n                                top_p=top_p if top_p else 0.7,\n                                temperature=temperature if temperature else 0.95)\n    now = datetime.datetime.now()\n    time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n    answer = {\n        \"response\": response,\n        \"history\": history,\n        \"status\": 200,\n        \"time\": time\n    }\n    log = \"[\" + time + \"] \" + '\", prompt:\"' + prompt + '\", response:\"' + repr(response) + '\"'\n    print(log)\n    torch_gc()\n    return answer\n\n\nif __name__ == '__main__':\n    tokenizer = AutoTokenizer.from_pretrained(\"internlm/internlm-chat-7b-v1_1\", trust_remote_code=True)\n    model = AutoModel.from_pretrained(\"internlm/internlm-chat-7b-v1_1\", trust_remote_code=True).half().cuda()\n    model.eval()\n    uvicorn.run(app, host='0.0.0.0', port=8000, workers=1)\n</code></pre>"},{"location":"blog/2023/09/11/%E8%87%AA%E5%AE%9A%E4%B9%89llm-api/#3","title":"3. \u200b\u7f16\u5199\u200b\u8c03\u7528\u200b\u63a5\u53e3\u200b\u90e8\u5206\u200b\u4ee3\u7801","text":"<p>\u200b\u5728\u200b\u4ee5\u4e0b\u200b\u9879\u76ee\u200b<code>knowledge_qa_llm/llm/</code>\u200b\u76ee\u5f55\u200b\u4e0b\u200b\u521b\u5efa\u200b<code>internlm_7b.py</code>\u200b\u6587\u4ef6\u200b\uff0c\u200b\u5177\u4f53\u200b\u4ee3\u7801\u200b\u5982\u4e0b\u200b\uff1a</p> <pre><code>import json\nfrom typing import List, Optional\n\nimport requests\n\n\nclass InternLM_7B:\n    def __init__(self, api_url: str = None):\n        self.api_url = api_url\n\n    def __call__(self, prompt: str, history: Optional[List] = None, **kwargs):\n        if not history:\n            history = []\n\n        data = {\"prompt\": prompt, \"history\": history}\n        if kwargs:\n            temperature = kwargs.get(\"temperature\", 0.1)\n            top_p = kwargs.get(\"top_p\", 0.7)\n            max_length = kwargs.get(\"max_length\", 4096)\n\n            data.update(\n                {\"temperature\": temperature, \"top_p\": top_p, \"max_length\": max_length}\n            )\n        req = requests.post(self.api_url, data=json.dumps(data), timeout=60)\n        try:\n            rdata = req.json()\n            if rdata[\"status\"] == 200:\n                return rdata[\"response\"]\n            return \"Network error\"\n        except Exception as e:\n            return f\"Network error:{e}\"\n</code></pre>"},{"location":"blog/2023/09/11/%E8%87%AA%E5%AE%9A%E4%B9%89llm-api/#4","title":"4. \u200b\u6dfb\u52a0\u200b\u5bfc\u5165\u200b\u58f0\u660e","text":"<p>\u200b\u5728\u200b<code>knowledge_qa_llm/llm/__init__.py</code>\u200b\u4e2d\u200b\u6dfb\u52a0\u200b\u5bf9\u5e94\u200b\u7684\u200b<code>import</code>\u200b\u90e8\u5206\u200b\u4ee3\u7801\u200b\uff0c\u200b\u793a\u4f8b\u200b\u5982\u4e0b\u200b\uff1a</p> <pre><code>from .baichuan_7b import BaiChuan7B\nfrom .chatglm2_6b import ChatGLM2_6B\nfrom .ernie_bot_turbo import ERNIEBotTurbo\nfrom .qwen7b_chat import Qwen7B_Chat\nfrom .internlm_7b import InternLM_7B\n\n__all__ = [\"BaiChuan7B\", \"ChatGLM2_6B\", \"ERNIEBotTurbo\", \"Qwen7B_Chat\", \"InternLM_7B\"]\n</code></pre>"},{"location":"blog/2023/09/11/%E8%87%AA%E5%AE%9A%E4%B9%89llm-api/#5","title":"5. \u200b\u66f4\u6539\u200b\u914d\u7f6e\u6587\u4ef6","text":"<p>\u200b\u66f4\u6539\u200b<code>knowledge_qa_llm/config.yaml</code></p> <pre><code>LLM_API:\n    InternLM_7B: your_api\n    Qwen7B_Chat: your_api\n    ChatGLM2_6B: your_api\n    BaiChuan7B: your_api\n</code></pre>"},{"location":"blog/2023/09/11/%E8%87%AA%E5%AE%9A%E4%B9%89llm-api/#6","title":"6. \u200b\u542f\u52a8","text":"<pre><code>streamlit run web_ui.py\n</code></pre>"},{"location":"blog/2023/09/11/%E6%94%AF%E6%8C%81%E7%9A%84llm/","title":"\u652f\u6301\u200b\u7684\u200bLLM","text":"<p>\u2705 ChatGLM2-6B</p> <p>\u2705 BaiChuan-7B</p> <p>\u2705 Qwen-7B</p> <p>\u2705 llama2</p> <p>\u2705 InternLM-7b</p>"},{"location":"blog/category/general/","title":"General","text":""}]}